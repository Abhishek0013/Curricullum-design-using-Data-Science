{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### open the chrome web driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"C:\\Program Files (x86)\\chromedriver.exe\"\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create the list of titles to search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = ['Analytics+Manager', 'Data+Scientist', 'Data+Engineer', 'Data+Analyst', 'Analytics+Manager', 'Business+Intelligence+Analyst']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scrap jobs and save to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for title_ in title_list:\n",
    "    \n",
    "    df = pd.DataFrame(columns=[\"Title\",\"Location\",\"Company\",\"Salary\",\"Sponsored\",\"Description\"])\n",
    "    \n",
    "    for i in range(0, 500, 50):\n",
    "\n",
    "        driver.get(f'https:///www.indeed.com/jobs?q=title%3A%28{title_}%29&l=United+States&jt=fulltime&sort=date&limit=50&start='+str(i))\n",
    "        driver.implicitly_wait(4)\n",
    "\n",
    "        for job in driver.find_elements_by_class_name('result'):\n",
    "\n",
    "            soup = BeautifulSoup(job.get_attribute('innerHTML'),'html.parser')\n",
    "\n",
    "            #title\n",
    "            try:\n",
    "                title = soup.find(\"a\",class_=\"jobtitle\").text.replace(\"\\n\",\"\").strip()\n",
    "            except:\n",
    "                title = 'None'\n",
    "                \n",
    "            #location\n",
    "            try:\n",
    "                location = soup.find(class_=\"location\").text\n",
    "            except:\n",
    "                location = 'None'\n",
    "\n",
    "            #company\n",
    "            try:\n",
    "                company = soup.find(class_=\"company\").text.replace(\"\\n\",\"\").strip()\n",
    "            except:\n",
    "                company = 'None'\n",
    "\n",
    "            #salary\n",
    "            try:\n",
    "                salary = soup.find(class_=\"salary\").text.replace(\"\\n\",\"\").strip()\n",
    "            except:\n",
    "                salary = 'None'\n",
    "\n",
    "            # sponsore flag\n",
    "            try:\n",
    "                sponsored = soup.find(class_=\"sponsoredGray\").text\n",
    "                sponsored = \"Sponsored\"\n",
    "            except:\n",
    "                sponsored = \"Organic\"\n",
    "\n",
    "\n",
    "            # click the job card to extract description\n",
    "            sum_div = job.find_element_by_xpath('./div[2]')\n",
    "            try:\n",
    "                sum_div.click()\n",
    "            except:\n",
    "                close_button = driver.find_elements_by_class_name('popover-x-button-close')[0]\n",
    "                close_button.click()\n",
    "                sum_div.click()\n",
    "\n",
    "            ## Give time for iframe to load\n",
    "            time.sleep(7.5)\n",
    "\n",
    "            try:\n",
    "                ## You have to switch to the iframe like so: ##\n",
    "                driver.switch_to.frame(driver.find_element_by_tag_name(\"iframe\"))\n",
    "                \n",
    "                try:\n",
    "                    ## Insert text via xpath ## //*[@id=\"jobDescriptionText\"]\n",
    "                    job_desc = driver.find_element_by_xpath('//*[@id=\"jobDescriptionText\"]').text\n",
    "                except:\n",
    "                    job_desc = 'None'\n",
    "                \n",
    "                ## Switch back to the \"default content\" (that is, out of the iframes) ##\n",
    "                driver.switch_to.default_content()\n",
    "            except:\n",
    "                job_desc = 'None'\n",
    "\n",
    "            # add to data frame\n",
    "            df = df.append({'Title':title,'Location':location,\"Company\":company,\"Salary\":salary,\n",
    "                            \"Sponsored\":sponsored,\"Description\":job_desc},ignore_index=True)\n",
    "\n",
    "    # save to csv file\n",
    "    df.to_csv(f'{title_}_US.csv',index=False)\n",
    "    del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the same script for Canada jobs by changing the url to CA domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### close the webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MIE1624_env",
   "language": "python",
   "name": "mie1624_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
